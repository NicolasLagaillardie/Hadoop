2018-09-24 15:58:01,388 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = lag-Predator-G3-571/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.1
STARTUP_MSG:   classpath = /home/lag/BD/Hadoop/hadoop-2.9.1/etc/hadoop:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/activation-1.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/xz-1.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/asm-3.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hadoop-auth-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jettison-1.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/junit-4.11.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/avro-1.7.7.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hadoop-annotations-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsch-0.1.54.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-common-2.9.1-tests.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-nfs-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-common-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-2.9.1-tests.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1-tests.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1-tests.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1-tests.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/fst-2.50.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-client-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-router-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-common-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-registry-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-api-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-common-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1-tests.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e30710aea4e6e55e69372929106cf119af06fd0e; compiled by 'root' on 2018-04-16T09:33Z
STARTUP_MSG:   java = 1.8.0_181
************************************************************/
2018-09-24 15:58:01,395 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2018-09-24 15:58:01,635 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-09-24 15:58:01,680 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-09-24 15:58:01,680 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2018-09-24 15:58:01,820 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2018-09-24 15:58:01,833 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-lag/dfs/namesecondary/in_use.lock acquired by nodename 7505@lag-Predator-G3-571
2018-09-24 15:58:01,840 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2018-09-24 15:58:01,841 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2018-09-24 15:58:01,842 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2018-09-24 15:58:01,842 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = lag (auth:SIMPLE)
2018-09-24 15:58:01,842 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2018-09-24 15:58:01,842 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2018-09-24 15:58:01,842 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2018-09-24 15:58:01,862 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2018-09-24 15:58:01,873 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2018-09-24 15:58:01,873 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2018-09-24 15:58:01,875 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2018-09-24 15:58:01,876 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2018 Sep 24 15:58:01
2018-09-24 15:58:01,877 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2018-09-24 15:58:01,877 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-24 15:58:01,878 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2018-09-24 15:58:01,878 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2018-09-24 15:58:01,888 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2018-09-24 15:58:01,888 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.heartbeat.interval(3) assuming SECONDS
2018-09-24 15:58:01,891 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2018-09-24 15:58:01,892 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2018-09-24 15:58:01,892 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2018-09-24 15:58:01,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2018-09-24 15:58:01,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2018-09-24 15:58:01,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2018-09-24 15:58:01,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2018-09-24 15:58:01,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2018-09-24 15:58:01,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2018-09-24 15:58:01,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2018-09-24 15:58:01,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2018-09-24 15:58:01,894 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2018-09-24 15:58:01,935 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2018-09-24 15:58:01,935 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-24 15:58:01,935 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2018-09-24 15:58:01,935 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2018-09-24 15:58:01,936 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2018-09-24 15:58:01,936 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2018-09-24 15:58:01,936 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2018-09-24 15:58:01,938 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: falseskipCaptureAccessTimeOnlyChange: false
2018-09-24 15:58:01,941 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2018-09-24 15:58:01,941 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-24 15:58:01,942 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2018-09-24 15:58:01,942 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2018-09-24 15:58:01,944 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2018-09-24 15:58:01,944 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2018-09-24 15:58:01,944 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2018-09-24 15:58:01,951 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2018-09-24 15:58:01,951 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2018-09-24 15:58:01,961 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2018-09-24 15:58:02,002 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-09-24 15:58:02,008 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-09-24 15:58:02,011 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2018-09-24 15:58:02,016 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-09-24 15:58:02,017 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2018-09-24 15:58:02,018 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-09-24 15:58:02,018 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-09-24 15:58:02,029 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2018-09-24 15:58:02,029 INFO org.mortbay.log: jetty-6.1.26
2018-09-24 15:58:02,187 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2018-09-24 15:58:02,187 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2018-09-24 15:59:03,225 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-24 15:59:04,227 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-24 15:59:05,229 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-24 15:59:06,230 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-24 15:59:07,231 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-24 15:59:08,232 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-24 15:59:09,234 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-24 15:59:10,235 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-24 15:59:11,237 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-24 15:59:12,238 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-24 15:59:12,245 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From lag-Predator-G3-571/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:754)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:129)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:687)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:790)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1554)
	at org.apache.hadoop.ipc.Client.call(Client.java:1385)
	... 22 more
2018-09-24 16:00:13,250 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-24 16:00:14,250 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-24 16:00:15,252 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-24 16:00:16,254 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-24 16:00:17,255 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-24 16:00:18,256 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-24 16:00:19,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-24 16:00:20,259 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-24 16:00:21,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-24 16:00:22,261 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-24 16:00:22,263 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From lag-Predator-G3-571/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:754)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:129)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:687)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:790)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1554)
	at org.apache.hadoop.ipc.Client.call(Client.java:1385)
	... 22 more
2018-09-24 16:31:22,706 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2018-09-24 16:31:23,063 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=0&storageInfo=-63:1438813254:1537797164589:CID-d46bcbf5-42c2-408a-a95e-5958aa5ec944&bootstrapstandby=false
2018-09-24 16:31:23,093 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2018-09-24 16:31:23,217 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000000000 took 0.00s.
2018-09-24 16:31:23,218 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 320 bytes.
2018-09-24 16:31:23,235 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1&endTxId=2&storageInfo=-63:1438813254:1537797164589:CID-d46bcbf5-42c2-408a-a95e-5958aa5ec944
2018-09-24 16:31:23,251 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-lag/dfs/namesecondary/current/edits_tmp_0000000000000000001-0000000000000000002_0000000000003620122 took 0.00s.
2018-09-24 16:31:23,251 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000000002_0000000000003620122 size 0 bytes.
2018-09-24 16:31:23,251 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=3&endTxId=954&storageInfo=-63:1438813254:1537797164589:CID-d46bcbf5-42c2-408a-a95e-5958aa5ec944
2018-09-24 16:31:23,267 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 91000.00 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-lag/dfs/namesecondary/current/edits_tmp_0000000000000000003-0000000000000000954_0000000000003620138 took 0.00s.
2018-09-24 16:31:23,267 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000003-0000000000000000954_0000000000003620138 size 0 bytes.
2018-09-24 16:31:23,307 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2018-09-24 16:31:23,324 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2018-09-24 16:31:23,325 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000000000
2018-09-24 16:31:23,325 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2018-09-24 16:31:23,329 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
2018-09-24 16:31:23,332 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002 expecting start txid #1
2018-09-24 16:31:23,332 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002
2018-09-24 16:31:23,345 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002 of size 42 edits # 2 loaded in 0 seconds
2018-09-24 16:31:23,345 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000003-0000000000000000954 expecting start txid #3
2018-09-24 16:31:23,345 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000003-0000000000000000954
2018-09-24 16:31:23,446 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000003-0000000000000000954 of size 93540 edits # 952 loaded in 0 seconds
2018-09-24 16:31:23,450 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000000954 using no compression
2018-09-24 16:31:23,484 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000000954 of size 12333 bytes saved in 0 seconds .
2018-09-24 16:31:23,494 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-lag/dfs/namesecondary
2018-09-24 16:31:23,499 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-lag/dfs/namesecondary
2018-09-24 16:31:23,534 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000000954, fileSize: 12333. Sent total: 12333 bytes. Size of last segment intended to send: -1 bytes.
2018-09-24 16:31:23,587 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 954 to namenode at http://localhost:50070 in 0.07 seconds
2018-09-24 16:31:23,588 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 12333
2018-09-24 15:31:23,586 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-24 15:31:23,586 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=955&endTxId=956&storageInfo=-63:1438813254:1537797164589:CID-d46bcbf5-42c2-408a-a95e-5958aa5ec944
2018-09-24 15:31:23,609 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-lag/dfs/namesecondary/current/edits_tmp_0000000000000000955-0000000000000000956_0000000000007220884 took 0.00s.
2018-09-24 15:31:23,609 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000955-0000000000000000956_0000000000007220884 size 0 bytes.
2018-09-24 15:31:23,609 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-24 15:31:23,609 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000955-0000000000000000956 expecting start txid #955
2018-09-24 15:31:23,609 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000955-0000000000000000956
2018-09-24 15:31:23,610 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000955-0000000000000000956 of size 42 edits # 2 loaded in 0 seconds
2018-09-24 15:31:23,610 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000000956 using no compression
2018-09-24 15:31:23,620 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000000956 of size 12333 bytes saved in 0 seconds .
2018-09-24 15:31:23,634 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 954
2018-09-24 15:31:23,634 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2018-09-24 15:31:23,644 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000000956, fileSize: 12333. Sent total: 12333 bytes. Size of last segment intended to send: -1 bytes.
2018-09-24 15:31:23,670 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 956 to namenode at http://localhost:50070 in 0.027 seconds
2018-09-24 15:31:23,671 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 12333
2018-09-24 16:03:39,640 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2018-09-24 16:03:39,643 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at lag-Predator-G3-571/127.0.1.1
************************************************************/
2018-09-24 16:04:35,825 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = lag-Predator-G3-571/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.1
STARTUP_MSG:   classpath = /home/lag/BD/Hadoop/hadoop-2.9.1/etc/hadoop:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/activation-1.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/xz-1.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/asm-3.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hadoop-auth-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jettison-1.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/junit-4.11.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/avro-1.7.7.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hadoop-annotations-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsch-0.1.54.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-common-2.9.1-tests.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-nfs-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-common-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-2.9.1-tests.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1-tests.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1-tests.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1-tests.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/fst-2.50.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-client-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-router-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-common-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-registry-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-api-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-common-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1-tests.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.1.jar:/usr/lib/jvm/java-8-openjdk-amd64//lib/tools.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e30710aea4e6e55e69372929106cf119af06fd0e; compiled by 'root' on 2018-04-16T09:33Z
STARTUP_MSG:   java = 1.8.0_181
************************************************************/
2018-09-24 16:04:35,835 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2018-09-24 16:04:36,099 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-09-24 16:04:36,153 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-09-24 16:04:36,153 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2018-09-24 16:04:36,297 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2018-09-24 16:04:36,348 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-lag/dfs/namesecondary/in_use.lock acquired by nodename 16063@lag-Predator-G3-571
2018-09-24 16:04:36,369 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2018-09-24 16:04:36,370 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2018-09-24 16:04:36,372 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2018-09-24 16:04:36,373 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = lag (auth:SIMPLE)
2018-09-24 16:04:36,373 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2018-09-24 16:04:36,373 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2018-09-24 16:04:36,373 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2018-09-24 16:04:36,400 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2018-09-24 16:04:36,412 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2018-09-24 16:04:36,412 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2018-09-24 16:04:36,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2018-09-24 16:04:36,415 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2018 Sep 24 16:04:36
2018-09-24 16:04:36,416 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2018-09-24 16:04:36,416 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-24 16:04:36,417 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2018-09-24 16:04:36,417 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2018-09-24 16:04:36,427 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2018-09-24 16:04:36,427 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.heartbeat.interval(3) assuming SECONDS
2018-09-24 16:04:36,431 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2018-09-24 16:04:36,432 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2018-09-24 16:04:36,432 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2018-09-24 16:04:36,432 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2018-09-24 16:04:36,432 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2018-09-24 16:04:36,432 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2018-09-24 16:04:36,432 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2018-09-24 16:04:36,432 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2018-09-24 16:04:36,432 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2018-09-24 16:04:36,432 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2018-09-24 16:04:36,432 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2018-09-24 16:04:36,435 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2018-09-24 16:04:36,481 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2018-09-24 16:04:36,481 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-24 16:04:36,481 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2018-09-24 16:04:36,481 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2018-09-24 16:04:36,482 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2018-09-24 16:04:36,482 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2018-09-24 16:04:36,482 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2018-09-24 16:04:36,484 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: falseskipCaptureAccessTimeOnlyChange: false
2018-09-24 16:04:36,487 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2018-09-24 16:04:36,487 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-24 16:04:36,487 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2018-09-24 16:04:36,487 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2018-09-24 16:04:36,490 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2018-09-24 16:04:36,490 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2018-09-24 16:04:36,490 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2018-09-24 16:04:36,496 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2018-09-24 16:04:36,496 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2018-09-24 16:04:36,506 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2018-09-24 16:04:36,553 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-09-24 16:04:36,561 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-09-24 16:04:36,566 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2018-09-24 16:04:36,572 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-09-24 16:04:36,574 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2018-09-24 16:04:36,574 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-09-24 16:04:36,574 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-09-24 16:04:36,586 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2018-09-24 16:04:36,586 INFO org.mortbay.log: jetty-6.1.26
2018-09-24 16:04:36,747 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2018-09-24 16:04:36,747 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2018-09-24 16:05:24,834 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2018-09-24 16:05:24,838 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at lag-Predator-G3-571/127.0.1.1
************************************************************/
2018-09-24 16:06:11,013 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = lag-Predator-G3-571/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.1
STARTUP_MSG:   classpath = /home/lag/BD/Hadoop/hadoop-2.9.1/etc/hadoop:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/activation-1.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/xz-1.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/asm-3.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hadoop-auth-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jettison-1.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/junit-4.11.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/avro-1.7.7.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hadoop-annotations-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsch-0.1.54.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-common-2.9.1-tests.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-nfs-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-common-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-2.9.1-tests.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1-tests.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1-tests.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1-tests.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/fst-2.50.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-client-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-router-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-common-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-registry-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-api-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-common-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1-tests.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.1.jar:/home/lag/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.1.jar:/usr/lib/jvm/java-8-openjdk-amd64//lib/tools.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e30710aea4e6e55e69372929106cf119af06fd0e; compiled by 'root' on 2018-04-16T09:33Z
STARTUP_MSG:   java = 1.8.0_181
************************************************************/
2018-09-24 16:06:11,020 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2018-09-24 16:06:11,261 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-09-24 16:06:11,309 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-09-24 16:06:11,310 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2018-09-24 16:06:11,456 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2018-09-24 16:06:11,472 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-lag/dfs/namesecondary/in_use.lock acquired by nodename 17227@lag-Predator-G3-571
2018-09-24 16:06:11,489 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2018-09-24 16:06:11,490 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2018-09-24 16:06:11,491 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2018-09-24 16:06:11,492 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = lag (auth:SIMPLE)
2018-09-24 16:06:11,492 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2018-09-24 16:06:11,492 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2018-09-24 16:06:11,492 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2018-09-24 16:06:11,516 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2018-09-24 16:06:11,529 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2018-09-24 16:06:11,529 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2018-09-24 16:06:11,531 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2018-09-24 16:06:11,531 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2018 Sep 24 16:06:11
2018-09-24 16:06:11,533 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2018-09-24 16:06:11,533 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-24 16:06:11,534 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2018-09-24 16:06:11,534 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2018-09-24 16:06:11,544 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2018-09-24 16:06:11,544 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.heartbeat.interval(3) assuming SECONDS
2018-09-24 16:06:11,548 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2018-09-24 16:06:11,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2018-09-24 16:06:11,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2018-09-24 16:06:11,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2018-09-24 16:06:11,549 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2018-09-24 16:06:11,550 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2018-09-24 16:06:11,550 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2018-09-24 16:06:11,550 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2018-09-24 16:06:11,550 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2018-09-24 16:06:11,550 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2018-09-24 16:06:11,550 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2018-09-24 16:06:11,552 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2018-09-24 16:06:11,597 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2018-09-24 16:06:11,597 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-24 16:06:11,597 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2018-09-24 16:06:11,597 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2018-09-24 16:06:11,597 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2018-09-24 16:06:11,598 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2018-09-24 16:06:11,598 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2018-09-24 16:06:11,600 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: falseskipCaptureAccessTimeOnlyChange: false
2018-09-24 16:06:11,603 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2018-09-24 16:06:11,603 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-24 16:06:11,603 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2018-09-24 16:06:11,603 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2018-09-24 16:06:11,606 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2018-09-24 16:06:11,606 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2018-09-24 16:06:11,606 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2018-09-24 16:06:11,613 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2018-09-24 16:06:11,614 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2018-09-24 16:06:11,621 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2018-09-24 16:06:11,666 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-09-24 16:06:11,672 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-09-24 16:06:11,677 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2018-09-24 16:06:11,681 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-09-24 16:06:11,683 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2018-09-24 16:06:11,683 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-09-24 16:06:11,683 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-09-24 16:06:11,695 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2018-09-24 16:06:11,696 INFO org.mortbay.log: jetty-6.1.26
2018-09-24 16:06:11,856 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2018-09-24 16:06:11,856 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2018-09-24 16:07:12,050 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2018-09-24 16:07:12,191 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=956&storageInfo=-63:1438813254:1537797164589:CID-d46bcbf5-42c2-408a-a95e-5958aa5ec944&bootstrapstandby=false
2018-09-24 16:07:12,207 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2018-09-24 16:07:12,358 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 4000.00 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000000956 took 0.00s.
2018-09-24 16:07:12,359 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000956 size 12333 bytes.
2018-09-24 16:07:12,375 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=957&endTxId=957&storageInfo=-63:1438813254:1537797164589:CID-d46bcbf5-42c2-408a-a95e-5958aa5ec944
2018-09-24 16:07:12,414 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 341333.33 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-lag/dfs/namesecondary/current/edits_tmp_0000000000000000957-0000000000000000957_0000000000009369672 took 0.00s.
2018-09-24 16:07:12,415 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000957-0000000000000000957_0000000000009369672 size 0 bytes.
2018-09-24 16:07:12,415 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=958&endTxId=958&storageInfo=-63:1438813254:1537797164589:CID-d46bcbf5-42c2-408a-a95e-5958aa5ec944
2018-09-24 16:07:12,454 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 341333.33 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-lag/dfs/namesecondary/current/edits_tmp_0000000000000000958-0000000000000000958_0000000000009369713 took 0.00s.
2018-09-24 16:07:12,455 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000958-0000000000000000958_0000000000009369713 size 0 bytes.
2018-09-24 16:07:12,455 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=959&endTxId=960&storageInfo=-63:1438813254:1537797164589:CID-d46bcbf5-42c2-408a-a95e-5958aa5ec944
2018-09-24 16:07:12,470 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-lag/dfs/namesecondary/current/edits_tmp_0000000000000000959-0000000000000000960_0000000000009369753 took 0.00s.
2018-09-24 16:07:12,471 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000959-0000000000000000960_0000000000009369753 size 0 bytes.
2018-09-24 16:07:12,513 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 160 INodes.
2018-09-24 16:07:12,550 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2018-09-24 16:07:12,550 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 956 from /tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000000956
2018-09-24 16:07:12,550 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2018-09-24 16:07:12,554 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 3 stream(s).
2018-09-24 16:07:12,557 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000957-0000000000000000957 expecting start txid #957
2018-09-24 16:07:12,557 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000957-0000000000000000957
2018-09-24 16:07:12,570 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000957-0000000000000000957 of size 1048576 edits # 1 loaded in 0 seconds
2018-09-24 16:07:12,570 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000958-0000000000000000958 expecting start txid #958
2018-09-24 16:07:12,570 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000958-0000000000000000958
2018-09-24 16:07:12,571 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000958-0000000000000000958 of size 1048576 edits # 1 loaded in 0 seconds
2018-09-24 16:07:12,571 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000959-0000000000000000960 expecting start txid #959
2018-09-24 16:07:12,571 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000959-0000000000000000960
2018-09-24 16:07:12,571 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000959-0000000000000000960 of size 42 edits # 2 loaded in 0 seconds
2018-09-24 16:07:12,575 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000000960 using no compression
2018-09-24 16:07:12,607 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000000960 of size 12333 bytes saved in 0 seconds .
2018-09-24 16:07:12,624 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 956
2018-09-24 16:07:12,624 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000000954, cpktTxId=0000000000000000954)
2018-09-24 16:07:12,659 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000000960, fileSize: 12333. Sent total: 12333 bytes. Size of last segment intended to send: -1 bytes.
2018-09-24 16:07:12,700 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 960 to namenode at http://localhost:50070 in 0.046 seconds
2018-09-24 16:07:12,700 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 12333
2018-09-24 16:40:18,184 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2018-09-24 16:40:18,186 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at lag-Predator-G3-571/127.0.1.1
************************************************************/
2018-09-28 13:33:10,670 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = lag-Predator-G3-571/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.1
STARTUP_MSG:   classpath = /home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/etc/hadoop:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/activation-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/xz-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hadoop-auth-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jettison-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/junit-4.11.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/avro-1.7.7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hadoop-annotations-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsch-0.1.54.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-common-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-nfs-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/fst-2.50.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-router-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-registry-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-api-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.1.jar:/usr/lib/jvm/java-8-openjdk-amd64//lib/tools.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e30710aea4e6e55e69372929106cf119af06fd0e; compiled by 'root' on 2018-04-16T09:33Z
STARTUP_MSG:   java = 1.8.0_181
************************************************************/
2018-09-28 13:33:10,719 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2018-09-28 13:33:10,853 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-28 13:33:10,950 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-09-28 13:33:10,992 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-09-28 13:33:10,992 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2018-09-28 13:33:11,115 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2018-09-28 13:33:11,150 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-lag/dfs/namesecondary/in_use.lock acquired by nodename 4892@lag-Predator-G3-571
2018-09-28 13:33:11,157 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2018-09-28 13:33:11,157 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2018-09-28 13:33:11,159 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2018-09-28 13:33:11,159 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = lag (auth:SIMPLE)
2018-09-28 13:33:11,159 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2018-09-28 13:33:11,159 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2018-09-28 13:33:11,159 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2018-09-28 13:33:11,175 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2018-09-28 13:33:11,184 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2018-09-28 13:33:11,184 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2018-09-28 13:33:11,186 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2018-09-28 13:33:11,186 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2018 Sep 28 13:33:11
2018-09-28 13:33:11,187 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2018-09-28 13:33:11,187 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-28 13:33:11,188 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2018-09-28 13:33:11,188 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2018-09-28 13:33:11,196 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2018-09-28 13:33:11,196 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.heartbeat.interval(3) assuming SECONDS
2018-09-28 13:33:11,199 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2018-09-28 13:33:11,200 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2018-09-28 13:33:11,200 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2018-09-28 13:33:11,200 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2018-09-28 13:33:11,200 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2018-09-28 13:33:11,200 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2018-09-28 13:33:11,200 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2018-09-28 13:33:11,200 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2018-09-28 13:33:11,200 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2018-09-28 13:33:11,200 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2018-09-28 13:33:11,200 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2018-09-28 13:33:11,201 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2018-09-28 13:33:11,242 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2018-09-28 13:33:11,242 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-28 13:33:11,242 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2018-09-28 13:33:11,242 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2018-09-28 13:33:11,243 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2018-09-28 13:33:11,243 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2018-09-28 13:33:11,243 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2018-09-28 13:33:11,244 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: falseskipCaptureAccessTimeOnlyChange: false
2018-09-28 13:33:11,247 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2018-09-28 13:33:11,247 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-28 13:33:11,247 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2018-09-28 13:33:11,247 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2018-09-28 13:33:11,249 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2018-09-28 13:33:11,249 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2018-09-28 13:33:11,249 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2018-09-28 13:33:11,256 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2018-09-28 13:33:11,256 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2018-09-28 13:33:11,261 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2018-09-28 13:33:11,293 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-09-28 13:33:11,298 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-09-28 13:33:11,302 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2018-09-28 13:33:11,305 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-09-28 13:33:11,307 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2018-09-28 13:33:11,307 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-09-28 13:33:11,307 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-09-28 13:33:11,317 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2018-09-28 13:33:11,317 INFO org.mortbay.log: jetty-6.1.26
2018-09-28 13:33:11,465 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2018-09-28 13:33:11,465 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2018-09-28 13:34:12,497 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:34:13,498 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:34:14,500 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:34:15,501 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:34:16,502 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:34:17,504 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:34:18,505 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:34:19,507 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:34:20,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:34:21,509 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:34:21,518 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From lag-Predator-G3-571/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:754)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:129)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:687)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:790)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1554)
	at org.apache.hadoop.ipc.Client.call(Client.java:1385)
	... 22 more
2018-09-28 13:35:22,528 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:35:23,529 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:35:24,531 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:35:25,532 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:35:26,533 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:35:27,534 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:35:28,535 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:35:29,537 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:35:30,538 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:35:31,539 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:35:31,541 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From lag-Predator-G3-571/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:754)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:129)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:687)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:790)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1554)
	at org.apache.hadoop.ipc.Client.call(Client.java:1385)
	... 22 more
2018-09-28 13:36:32,546 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:36:33,547 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:36:34,548 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:36:35,549 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:36:36,550 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:36:37,551 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:36:38,552 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:36:39,553 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:36:40,554 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:36:41,556 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:36:41,557 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From lag-Predator-G3-571/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:754)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:129)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:687)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:790)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1554)
	at org.apache.hadoop.ipc.Client.call(Client.java:1385)
	... 22 more
2018-09-28 13:37:42,563 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:37:43,564 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:37:44,565 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:37:45,567 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:37:46,568 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:37:47,569 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:37:48,570 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:37:49,572 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:37:50,573 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:37:51,574 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:37:51,576 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From lag-Predator-G3-571/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:754)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:129)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:687)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:790)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1554)
	at org.apache.hadoop.ipc.Client.call(Client.java:1385)
	... 22 more
2018-09-28 13:38:52,581 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:38:53,582 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:38:54,583 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:38:55,584 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:38:56,586 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:38:57,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:38:58,588 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:38:59,589 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:39:00,590 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:39:01,591 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:39:01,593 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From lag-Predator-G3-571/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:754)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:129)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:687)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:790)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1554)
	at org.apache.hadoop.ipc.Client.call(Client.java:1385)
	... 22 more
2018-09-28 13:40:02,598 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:40:03,599 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:40:04,600 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:40:05,601 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:40:06,603 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:40:07,604 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:40:08,605 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:40:09,606 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:40:10,607 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:40:11,608 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:40:11,610 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From lag-Predator-G3-571/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:754)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:129)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:687)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:790)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1554)
	at org.apache.hadoop.ipc.Client.call(Client.java:1385)
	... 22 more
2018-09-28 13:41:12,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:41:13,616 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:41:14,617 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:41:15,618 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:41:16,619 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:41:17,620 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:41:18,621 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:41:19,622 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:41:20,623 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:41:21,625 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:41:21,626 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From lag-Predator-G3-571/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:754)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:129)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:687)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:790)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1554)
	at org.apache.hadoop.ipc.Client.call(Client.java:1385)
	... 22 more
2018-09-28 13:42:22,631 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:42:23,632 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:42:24,632 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:42:25,634 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:42:26,635 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:42:27,636 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:42:28,637 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:42:29,638 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:42:30,640 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:42:31,641 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:42:31,642 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From lag-Predator-G3-571/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:754)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:129)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:687)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:790)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1554)
	at org.apache.hadoop.ipc.Client.call(Client.java:1385)
	... 22 more
2018-09-28 13:43:32,645 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:43:33,646 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:43:34,648 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:43:35,649 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:43:36,650 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:43:37,651 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:43:38,652 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:43:39,653 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:43:40,654 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:43:41,656 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:43:41,657 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From lag-Predator-G3-571/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:754)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:129)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:687)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:790)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1554)
	at org.apache.hadoop.ipc.Client.call(Client.java:1385)
	... 22 more
2018-09-28 13:44:42,660 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:44:43,661 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:44:44,662 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:44:45,663 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:44:46,664 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:44:47,665 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:44:48,667 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:44:49,668 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:44:50,669 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:44:51,670 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:44:51,671 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From lag-Predator-G3-571/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:754)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:129)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:687)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:790)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1554)
	at org.apache.hadoop.ipc.Client.call(Client.java:1385)
	... 22 more
2018-09-28 13:45:52,676 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:45:53,677 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:45:54,678 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:45:55,679 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:45:56,680 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:45:57,681 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:45:58,682 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:45:59,683 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:46:00,685 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:46:01,686 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:46:01,687 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From lag-Predator-G3-571/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:754)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:129)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:687)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:790)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1554)
	at org.apache.hadoop.ipc.Client.call(Client.java:1385)
	... 22 more
2018-09-28 13:47:02,689 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:47:03,690 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:47:04,690 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:47:05,691 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:47:06,692 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:47:07,692 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:47:08,693 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:47:09,694 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:47:10,695 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:47:11,696 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:47:11,697 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From lag-Predator-G3-571/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:754)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:129)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:687)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:790)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1554)
	at org.apache.hadoop.ipc.Client.call(Client.java:1385)
	... 22 more
2018-09-28 13:48:12,699 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:48:13,700 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:48:14,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:48:15,702 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:48:16,703 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:48:17,704 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:48:18,705 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:48:19,706 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:48:20,707 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:48:21,708 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:48:21,709 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From lag-Predator-G3-571/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:754)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:129)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:687)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:790)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1554)
	at org.apache.hadoop.ipc.Client.call(Client.java:1385)
	... 22 more
2018-09-28 13:49:22,712 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:49:23,713 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:49:24,714 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:49:25,715 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:49:26,716 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:49:27,717 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:49:28,718 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:49:29,719 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:49:30,720 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:49:31,721 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:49:31,722 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From lag-Predator-G3-571/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:754)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:129)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:687)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:790)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1554)
	at org.apache.hadoop.ipc.Client.call(Client.java:1385)
	... 22 more
2018-09-28 13:50:32,727 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:50:33,728 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:50:34,729 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:50:35,730 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:50:36,732 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:50:37,733 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:50:38,734 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:50:39,735 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:50:40,736 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:50:41,737 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:50:41,739 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From lag-Predator-G3-571/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:754)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:129)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:687)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:790)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1554)
	at org.apache.hadoop.ipc.Client.call(Client.java:1385)
	... 22 more
2018-09-28 13:51:42,743 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:51:43,745 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:51:44,746 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:51:45,747 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:51:46,748 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:51:47,749 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:51:48,750 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:51:49,751 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:51:50,753 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:51:51,754 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:51:51,756 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From lag-Predator-G3-571/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:754)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:129)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:687)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:790)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1554)
	at org.apache.hadoop.ipc.Client.call(Client.java:1385)
	... 22 more
2018-09-28 13:52:52,759 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:52:53,760 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:52:54,762 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:52:55,762 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:52:56,764 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:52:57,765 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:52:58,766 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:52:59,767 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:53:00,768 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:53:01,770 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:53:01,771 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From lag-Predator-G3-571/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor2.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:754)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:129)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:687)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:790)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1554)
	at org.apache.hadoop.ipc.Client.call(Client.java:1385)
	... 21 more
2018-09-28 13:54:02,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:54:03,776 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:54:04,777 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:54:05,779 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:54:06,780 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:54:07,781 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:54:08,783 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:54:09,784 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:54:10,785 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:54:11,786 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:54:11,787 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From lag-Predator-G3-571/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor2.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:754)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:129)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:687)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:790)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1554)
	at org.apache.hadoop.ipc.Client.call(Client.java:1385)
	... 21 more
2018-09-28 13:55:12,791 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:55:13,792 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:55:14,793 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:55:15,795 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:55:16,796 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:55:17,797 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:55:18,798 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:55:19,799 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:55:20,800 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:55:21,801 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:55:21,802 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From lag-Predator-G3-571/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor2.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:754)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:129)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:687)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:790)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1554)
	at org.apache.hadoop.ipc.Client.call(Client.java:1385)
	... 21 more
2018-09-28 13:56:22,806 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:56:23,807 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:56:24,808 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:56:25,808 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:56:26,809 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:56:27,810 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:56:28,811 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:56:29,812 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:56:30,813 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:56:31,814 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:56:31,815 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From lag-Predator-G3-571/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor2.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:754)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:129)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:687)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:790)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1554)
	at org.apache.hadoop.ipc.Client.call(Client.java:1385)
	... 21 more
2018-09-28 13:57:32,818 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:57:33,819 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:57:34,820 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:57:35,821 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:57:36,821 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:57:37,822 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:57:38,823 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:57:39,824 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:57:40,825 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:57:41,825 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:57:41,826 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From lag-Predator-G3-571/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor2.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:754)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:129)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:687)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:790)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1554)
	at org.apache.hadoop.ipc.Client.call(Client.java:1385)
	... 21 more
2018-09-28 13:58:42,829 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:58:43,830 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:58:44,832 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:58:45,833 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:58:46,834 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:58:47,836 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:58:48,837 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:58:49,838 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:58:50,840 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:58:51,841 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:58:51,842 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From lag-Predator-G3-571/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor2.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:754)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:129)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:687)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:790)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1554)
	at org.apache.hadoop.ipc.Client.call(Client.java:1385)
	... 21 more
2018-09-28 13:59:52,847 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:59:53,848 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:59:54,849 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:59:55,851 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 13:59:56,829 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2018-09-28 13:59:56,832 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at lag-Predator-G3-571/127.0.1.1
************************************************************/
2018-09-28 14:00:22,010 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = lag-Predator-G3-571/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.1
STARTUP_MSG:   classpath = /home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/etc/hadoop:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/activation-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/xz-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hadoop-auth-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jettison-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/junit-4.11.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/avro-1.7.7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hadoop-annotations-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsch-0.1.54.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-common-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-nfs-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/fst-2.50.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-router-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-registry-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-api-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.1.jar:/usr/lib/jvm/java-8-openjdk-amd64//lib/tools.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e30710aea4e6e55e69372929106cf119af06fd0e; compiled by 'root' on 2018-04-16T09:33Z
STARTUP_MSG:   java = 1.8.0_181
************************************************************/
2018-09-28 14:00:22,018 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2018-09-28 14:00:22,245 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-09-28 14:00:22,285 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-09-28 14:00:22,285 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2018-09-28 14:00:22,398 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2018-09-28 14:00:22,454 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-lag/dfs/namesecondary/in_use.lock acquired by nodename 7528@lag-Predator-G3-571
2018-09-28 14:00:22,479 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2018-09-28 14:00:22,480 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2018-09-28 14:00:22,483 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2018-09-28 14:00:22,483 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = lag (auth:SIMPLE)
2018-09-28 14:00:22,483 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2018-09-28 14:00:22,483 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2018-09-28 14:00:22,483 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2018-09-28 14:00:22,505 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2018-09-28 14:00:22,514 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2018-09-28 14:00:22,514 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2018-09-28 14:00:22,516 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2018-09-28 14:00:22,516 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2018 Sep 28 14:00:22
2018-09-28 14:00:22,517 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2018-09-28 14:00:22,517 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-28 14:00:22,518 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2018-09-28 14:00:22,518 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2018-09-28 14:00:22,525 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2018-09-28 14:00:22,525 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.heartbeat.interval(3) assuming SECONDS
2018-09-28 14:00:22,527 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2018-09-28 14:00:22,529 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2018-09-28 14:00:22,529 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2018-09-28 14:00:22,529 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2018-09-28 14:00:22,529 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2018-09-28 14:00:22,529 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2018-09-28 14:00:22,529 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2018-09-28 14:00:22,529 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2018-09-28 14:00:22,529 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2018-09-28 14:00:22,529 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2018-09-28 14:00:22,529 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2018-09-28 14:00:22,531 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2018-09-28 14:00:22,569 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2018-09-28 14:00:22,569 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-28 14:00:22,569 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2018-09-28 14:00:22,569 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2018-09-28 14:00:22,569 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2018-09-28 14:00:22,569 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2018-09-28 14:00:22,570 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2018-09-28 14:00:22,571 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: falseskipCaptureAccessTimeOnlyChange: false
2018-09-28 14:00:22,574 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2018-09-28 14:00:22,574 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-28 14:00:22,574 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2018-09-28 14:00:22,574 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2018-09-28 14:00:22,576 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2018-09-28 14:00:22,576 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2018-09-28 14:00:22,576 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2018-09-28 14:00:22,582 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2018-09-28 14:00:22,582 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2018-09-28 14:00:22,588 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2018-09-28 14:00:22,628 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-09-28 14:00:22,635 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-09-28 14:00:22,639 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2018-09-28 14:00:22,644 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-09-28 14:00:22,645 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2018-09-28 14:00:22,646 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-09-28 14:00:22,646 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-09-28 14:00:22,656 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2018-09-28 14:00:22,656 INFO org.mortbay.log: jetty-6.1.26
2018-09-28 14:00:22,787 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2018-09-28 14:00:22,787 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2018-09-28 14:01:23,816 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 14:01:24,818 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 14:01:25,819 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 14:01:26,821 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 14:01:27,822 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 14:01:28,824 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 14:01:29,825 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 14:01:30,826 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 14:01:31,828 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 14:01:32,829 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 14:01:32,835 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From lag-Predator-G3-571/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:754)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:129)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:687)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:790)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1554)
	at org.apache.hadoop.ipc.Client.call(Client.java:1385)
	... 22 more
2018-09-28 14:02:33,840 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 14:02:34,841 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 14:02:35,842 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 14:02:36,843 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 14:02:37,844 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 14:02:38,845 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 14:02:39,845 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 14:02:40,846 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 14:02:41,847 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 14:02:42,848 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-28 14:02:42,850 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.net.ConnectException: Call From lag-Predator-G3-571/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:754)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy10.getTransactionId(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.getTransactionID(NamenodeProtocolTranslatorPB.java:129)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy11.getTransactionID(Unknown Source)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.countUncheckpointedTxns(SecondaryNameNode.java:660)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.shouldCheckpointBasedOnCount(SecondaryNameNode.java:668)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:358)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:687)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:790)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1554)
	at org.apache.hadoop.ipc.Client.call(Client.java:1385)
	... 22 more
2018-09-28 14:03:01,479 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2018-09-28 14:03:01,482 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at lag-Predator-G3-571/127.0.1.1
************************************************************/
2018-09-28 14:03:24,446 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = lag-Predator-G3-571/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.1
STARTUP_MSG:   classpath = /home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/etc/hadoop:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/activation-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/xz-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hadoop-auth-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jettison-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/junit-4.11.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/avro-1.7.7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hadoop-annotations-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsch-0.1.54.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-common-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-nfs-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/fst-2.50.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-router-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-registry-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-api-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.1.jar:/usr/lib/jvm/java-8-openjdk-amd64//lib/tools.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e30710aea4e6e55e69372929106cf119af06fd0e; compiled by 'root' on 2018-04-16T09:33Z
STARTUP_MSG:   java = 1.8.0_181
************************************************************/
2018-09-28 14:03:24,451 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2018-09-28 14:03:24,653 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-09-28 14:03:24,693 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-09-28 14:03:24,694 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2018-09-28 14:03:24,806 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2018-09-28 14:03:24,836 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-lag/dfs/namesecondary/in_use.lock acquired by nodename 8933@lag-Predator-G3-571
2018-09-28 14:03:24,855 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2018-09-28 14:03:24,857 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2018-09-28 14:03:24,860 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2018-09-28 14:03:24,860 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = lag (auth:SIMPLE)
2018-09-28 14:03:24,861 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2018-09-28 14:03:24,861 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2018-09-28 14:03:24,861 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2018-09-28 14:03:24,885 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2018-09-28 14:03:24,895 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2018-09-28 14:03:24,895 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2018-09-28 14:03:24,897 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2018-09-28 14:03:24,897 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2018 Sep 28 14:03:24
2018-09-28 14:03:24,898 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2018-09-28 14:03:24,898 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-28 14:03:24,899 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2018-09-28 14:03:24,899 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2018-09-28 14:03:24,906 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2018-09-28 14:03:24,907 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.heartbeat.interval(3) assuming SECONDS
2018-09-28 14:03:24,909 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2018-09-28 14:03:24,910 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2018-09-28 14:03:24,910 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2018-09-28 14:03:24,910 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2018-09-28 14:03:24,910 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2018-09-28 14:03:24,910 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2018-09-28 14:03:24,910 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2018-09-28 14:03:24,910 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2018-09-28 14:03:24,910 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2018-09-28 14:03:24,910 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2018-09-28 14:03:24,910 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2018-09-28 14:03:24,912 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2018-09-28 14:03:24,950 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2018-09-28 14:03:24,950 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-28 14:03:24,950 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2018-09-28 14:03:24,951 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2018-09-28 14:03:24,951 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2018-09-28 14:03:24,951 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2018-09-28 14:03:24,951 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2018-09-28 14:03:24,953 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: falseskipCaptureAccessTimeOnlyChange: false
2018-09-28 14:03:24,955 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2018-09-28 14:03:24,955 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-28 14:03:24,955 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2018-09-28 14:03:24,955 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2018-09-28 14:03:24,957 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2018-09-28 14:03:24,957 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2018-09-28 14:03:24,957 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2018-09-28 14:03:24,963 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2018-09-28 14:03:24,963 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2018-09-28 14:03:24,967 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2018-09-28 14:03:25,007 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-09-28 14:03:25,014 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-09-28 14:03:25,017 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2018-09-28 14:03:25,021 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-09-28 14:03:25,022 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2018-09-28 14:03:25,022 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-09-28 14:03:25,022 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-09-28 14:03:25,031 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2018-09-28 14:03:25,031 INFO org.mortbay.log: jetty-6.1.26
2018-09-28 14:03:25,160 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2018-09-28 14:03:25,160 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2018-09-28 14:26:25,556 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2018-09-28 14:26:25,952 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=0&storageInfo=-63:1348204911:1538136165972:CID-d70c2304-fa4f-4780-840f-ce1e822c5a3d&bootstrapstandby=false
2018-09-28 14:26:26,002 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2018-09-28 14:26:26,120 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000000000 took 0.00s.
2018-09-28 14:26:26,120 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 320 bytes.
2018-09-28 14:26:26,129 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1&endTxId=2&storageInfo=-63:1348204911:1538136165972:CID-d70c2304-fa4f-4780-840f-ce1e822c5a3d
2018-09-28 14:26:26,136 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-lag/dfs/namesecondary/current/edits_tmp_0000000000000000001-0000000000000000002_0000000000003633572 took 0.00s.
2018-09-28 14:26:26,136 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000000002_0000000000003633572 size 0 bytes.
2018-09-28 14:26:26,174 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2018-09-28 14:26:26,191 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2018-09-28 14:26:26,191 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000000000
2018-09-28 14:26:26,191 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2018-09-28 14:26:26,194 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-28 14:26:26,197 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002 expecting start txid #1
2018-09-28 14:26:26,197 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002
2018-09-28 14:26:26,210 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002 of size 42 edits # 2 loaded in 0 seconds
2018-09-28 14:26:26,213 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000000002 using no compression
2018-09-28 14:26:26,232 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000000002 of size 320 bytes saved in 0 seconds .
2018-09-28 14:26:26,246 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-lag/dfs/namesecondary
2018-09-28 14:26:26,257 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-lag/dfs/namesecondary
2018-09-28 14:26:26,305 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000000002, fileSize: 320. Sent total: 320 bytes. Size of last segment intended to send: -1 bytes.
2018-09-28 14:26:26,344 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 2 to namenode at http://localhost:50070 in 0.055 seconds
2018-09-28 14:26:26,344 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 320
2018-09-28 15:13:10,691 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2018-09-28 15:13:10,694 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at lag-Predator-G3-571/127.0.1.1
************************************************************/
2018-09-28 15:16:11,981 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = lag-Predator-G3-571/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.1
STARTUP_MSG:   classpath = /home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/etc/hadoop:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/activation-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/xz-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hadoop-auth-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jettison-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/junit-4.11.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/avro-1.7.7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hadoop-annotations-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsch-0.1.54.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-common-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-nfs-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/fst-2.50.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-router-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-registry-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-api-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.1.jar:/usr/lib/jvm/java-11-openjdk-amd64//lib/tools.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e30710aea4e6e55e69372929106cf119af06fd0e; compiled by 'root' on 2018-04-16T09:33Z
STARTUP_MSG:   java = 10.0.2
************************************************************/
2018-09-28 15:16:11,987 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2018-09-28 15:16:12,258 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-09-28 15:16:12,346 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-09-28 15:16:12,346 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2018-09-28 15:16:12,484 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2018-09-28 15:16:12,515 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-lag/dfs/namesecondary/in_use.lock acquired by nodename 16429@lag-Predator-G3-571
2018-09-28 15:16:12,536 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2018-09-28 15:16:12,537 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2018-09-28 15:16:12,538 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2018-09-28 15:16:12,538 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = lag (auth:SIMPLE)
2018-09-28 15:16:12,538 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2018-09-28 15:16:12,538 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2018-09-28 15:16:12,538 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2018-09-28 15:16:12,559 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2018-09-28 15:16:12,572 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2018-09-28 15:16:12,572 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2018-09-28 15:16:12,575 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2018-09-28 15:16:12,575 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2018 Sep 28 15:16:12
2018-09-28 15:16:12,576 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2018-09-28 15:16:12,577 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-28 15:16:12,577 INFO org.apache.hadoop.util.GSet: 2.0% max memory 1000 MB = 20 MB
2018-09-28 15:16:12,578 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2018-09-28 15:16:12,590 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2018-09-28 15:16:12,590 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.heartbeat.interval(3) assuming SECONDS
2018-09-28 15:16:12,592 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2018-09-28 15:16:12,594 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2018-09-28 15:16:12,594 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2018-09-28 15:16:12,594 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2018-09-28 15:16:12,594 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2018-09-28 15:16:12,594 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2018-09-28 15:16:12,594 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2018-09-28 15:16:12,594 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2018-09-28 15:16:12,594 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2018-09-28 15:16:12,594 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2018-09-28 15:16:12,594 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2018-09-28 15:16:12,595 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2018-09-28 15:16:12,633 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2018-09-28 15:16:12,633 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-28 15:16:12,633 INFO org.apache.hadoop.util.GSet: 1.0% max memory 1000 MB = 10 MB
2018-09-28 15:16:12,633 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2018-09-28 15:16:12,635 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2018-09-28 15:16:12,635 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2018-09-28 15:16:12,635 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2018-09-28 15:16:12,637 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: falseskipCaptureAccessTimeOnlyChange: false
2018-09-28 15:16:12,639 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2018-09-28 15:16:12,640 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-28 15:16:12,640 INFO org.apache.hadoop.util.GSet: 0.25% max memory 1000 MB = 2.5 MB
2018-09-28 15:16:12,640 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2018-09-28 15:16:12,642 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2018-09-28 15:16:12,643 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2018-09-28 15:16:12,643 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2018-09-28 15:16:12,650 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2018-09-28 15:16:12,650 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2018-09-28 15:16:12,656 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2018-09-28 15:16:12,695 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-09-28 15:16:12,700 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-09-28 15:16:12,703 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2018-09-28 15:16:12,706 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-09-28 15:16:12,708 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2018-09-28 15:16:12,708 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-09-28 15:16:12,708 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-09-28 15:16:12,719 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2018-09-28 15:16:12,719 INFO org.mortbay.log: jetty-6.1.26
2018-09-28 15:16:12,814 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2018-09-28 15:16:12,815 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2018-09-28 15:17:13,036 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1587173570 cTime = 1538140556715 ; clusterId = CID-22e9083d-b89d-4af4-913a-65111140e42e ; blockpoolId = BP-196754129-127.0.1.1-1538140556715.
Expecting respectively: -63; 1348204911; 1538136165972; CID-d70c2304-fa4f-4780-840f-ce1e822c5a3d; BP-919151384-127.0.1.1-1538136165972.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.base/java.lang.Thread.run(Thread.java:844)
2018-09-28 15:18:13,119 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1587173570 cTime = 1538140556715 ; clusterId = CID-22e9083d-b89d-4af4-913a-65111140e42e ; blockpoolId = BP-196754129-127.0.1.1-1538140556715.
Expecting respectively: -63; 1348204911; 1538136165972; CID-d70c2304-fa4f-4780-840f-ce1e822c5a3d; BP-919151384-127.0.1.1-1538136165972.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.base/java.lang.Thread.run(Thread.java:844)
2018-09-28 15:19:13,204 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1587173570 cTime = 1538140556715 ; clusterId = CID-22e9083d-b89d-4af4-913a-65111140e42e ; blockpoolId = BP-196754129-127.0.1.1-1538140556715.
Expecting respectively: -63; 1348204911; 1538136165972; CID-d70c2304-fa4f-4780-840f-ce1e822c5a3d; BP-919151384-127.0.1.1-1538136165972.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.base/java.lang.Thread.run(Thread.java:844)
2018-09-28 15:20:13,294 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1587173570 cTime = 1538140556715 ; clusterId = CID-22e9083d-b89d-4af4-913a-65111140e42e ; blockpoolId = BP-196754129-127.0.1.1-1538140556715.
Expecting respectively: -63; 1348204911; 1538136165972; CID-d70c2304-fa4f-4780-840f-ce1e822c5a3d; BP-919151384-127.0.1.1-1538136165972.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.base/java.lang.Thread.run(Thread.java:844)
2018-09-28 15:21:13,377 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1587173570 cTime = 1538140556715 ; clusterId = CID-22e9083d-b89d-4af4-913a-65111140e42e ; blockpoolId = BP-196754129-127.0.1.1-1538140556715.
Expecting respectively: -63; 1348204911; 1538136165972; CID-d70c2304-fa4f-4780-840f-ce1e822c5a3d; BP-919151384-127.0.1.1-1538136165972.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.base/java.lang.Thread.run(Thread.java:844)
2018-09-28 15:22:13,454 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -63 namespaceID = 1587173570 cTime = 1538140556715 ; clusterId = CID-22e9083d-b89d-4af4-913a-65111140e42e ; blockpoolId = BP-196754129-127.0.1.1-1538140556715.
Expecting respectively: -63; 1348204911; 1538136165972; CID-d70c2304-fa4f-4780-840f-ce1e822c5a3d; BP-919151384-127.0.1.1-1538136165972.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:134)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.base/java.lang.Thread.run(Thread.java:844)
2018-09-28 15:22:22,555 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2018-09-28 15:22:22,559 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at lag-Predator-G3-571/127.0.1.1
************************************************************/
2018-09-29 13:13:23,156 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = lag-Predator-G3-571/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.1
STARTUP_MSG:   classpath = /home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/etc/hadoop:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/activation-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/xz-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hadoop-auth-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jettison-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/junit-4.11.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/avro-1.7.7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hadoop-annotations-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsch-0.1.54.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-common-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-nfs-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/fst-2.50.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-router-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-registry-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-api-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.1.jar:/usr/lib/jvm/java-11-openjdk-amd64//lib/tools.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e30710aea4e6e55e69372929106cf119af06fd0e; compiled by 'root' on 2018-04-16T09:33Z
STARTUP_MSG:   java = 10.0.2
************************************************************/
2018-09-29 13:13:23,193 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2018-09-29 13:13:23,473 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-09-29 13:13:23,564 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-09-29 13:13:23,564 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2018-09-29 13:13:23,699 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2018-09-29 13:13:23,748 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-lag/dfs/namesecondary/in_use.lock acquired by nodename 4923@lag-Predator-G3-571
2018-09-29 13:13:23,769 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2018-09-29 13:13:23,770 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2018-09-29 13:13:23,772 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2018-09-29 13:13:23,772 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = lag (auth:SIMPLE)
2018-09-29 13:13:23,772 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2018-09-29 13:13:23,772 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2018-09-29 13:13:23,772 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2018-09-29 13:13:23,798 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2018-09-29 13:13:23,814 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2018-09-29 13:13:23,814 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2018-09-29 13:13:23,817 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2018-09-29 13:13:23,818 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2018 Sep 29 13:13:23
2018-09-29 13:13:23,819 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2018-09-29 13:13:23,819 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-29 13:13:23,820 INFO org.apache.hadoop.util.GSet: 2.0% max memory 1000 MB = 20 MB
2018-09-29 13:13:23,820 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2018-09-29 13:13:23,833 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2018-09-29 13:13:23,833 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.heartbeat.interval(3) assuming SECONDS
2018-09-29 13:13:23,836 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2018-09-29 13:13:23,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2018-09-29 13:13:23,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2018-09-29 13:13:23,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2018-09-29 13:13:23,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2018-09-29 13:13:23,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2018-09-29 13:13:23,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2018-09-29 13:13:23,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2018-09-29 13:13:23,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2018-09-29 13:13:23,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2018-09-29 13:13:23,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2018-09-29 13:13:23,838 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2018-09-29 13:13:23,873 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2018-09-29 13:13:23,874 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-29 13:13:23,874 INFO org.apache.hadoop.util.GSet: 1.0% max memory 1000 MB = 10 MB
2018-09-29 13:13:23,874 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2018-09-29 13:13:23,875 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2018-09-29 13:13:23,875 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2018-09-29 13:13:23,875 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2018-09-29 13:13:23,878 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: falseskipCaptureAccessTimeOnlyChange: false
2018-09-29 13:13:23,880 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2018-09-29 13:13:23,880 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-09-29 13:13:23,881 INFO org.apache.hadoop.util.GSet: 0.25% max memory 1000 MB = 2.5 MB
2018-09-29 13:13:23,881 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2018-09-29 13:13:23,883 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2018-09-29 13:13:23,883 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2018-09-29 13:13:23,883 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2018-09-29 13:13:23,890 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2018-09-29 13:13:23,890 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2018-09-29 13:13:23,895 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2018-09-29 13:13:23,933 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-09-29 13:13:23,939 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-09-29 13:13:23,943 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2018-09-29 13:13:23,947 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-09-29 13:13:23,948 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2018-09-29 13:13:23,948 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-09-29 13:13:23,948 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-09-29 13:13:23,960 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2018-09-29 13:13:23,960 INFO org.mortbay.log: jetty-6.1.26
2018-09-29 13:13:24,071 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2018-09-29 13:13:24,071 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2018-09-29 13:14:24,319 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2018-09-29 13:14:25,100 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=0&storageInfo=-63:599153523:1538219587368:CID-88860281-4205-4492-aa60-05a152b2daf2&bootstrapstandby=false
2018-09-29 13:14:25,146 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2018-09-29 13:14:25,327 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.02s. The fsimage download took 0.02s at 0.00 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000000000 took 0.00s.
2018-09-29 13:14:25,327 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 320 bytes.
2018-09-29 13:14:25,335 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1&endTxId=87&storageInfo=-63:599153523:1538219587368:CID-88860281-4205-4492-aa60-05a152b2daf2
2018-09-29 13:14:25,340 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 7000.00 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-lag/dfs/namesecondary/current/edits_tmp_0000000000000000001-0000000000000000087_0000000000004228095 took 0.00s.
2018-09-29 13:14:25,341 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000000087_0000000000004228095 size 0 bytes.
2018-09-29 13:14:25,383 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2018-09-29 13:14:25,397 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2018-09-29 13:14:25,397 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000000000
2018-09-29 13:14:25,397 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2018-09-29 13:14:25,400 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-29 13:14:25,403 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000087 expecting start txid #1
2018-09-29 13:14:25,403 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000087
2018-09-29 13:14:25,451 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000087 of size 7878 edits # 87 loaded in 0 seconds
2018-09-29 13:14:25,454 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000000087 using no compression
2018-09-29 13:14:25,475 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000000087 of size 1659 bytes saved in 0 seconds .
2018-09-29 13:14:25,490 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-lag/dfs/namesecondary
2018-09-29 13:14:25,503 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-lag/dfs/namesecondary
2018-09-29 13:14:25,547 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000000087, fileSize: 1659. Sent total: 1659 bytes. Size of last segment intended to send: -1 bytes.
2018-09-29 13:14:25,587 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 87 to namenode at http://localhost:50070 in 0.064 seconds
2018-09-29 13:14:25,587 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 1659
2018-09-29 14:14:26,253 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-29 14:14:26,254 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=88&endTxId=1256&storageInfo=-63:599153523:1538219587368:CID-88860281-4205-4492-aa60-05a152b2daf2
2018-09-29 14:14:26,280 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 107000.00 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-lag/dfs/namesecondary/current/edits_tmp_0000000000000000088-0000000000000001256_0000000000007829015 took 0.00s.
2018-09-29 14:14:26,280 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000088-0000000000000001256_0000000000007829015 size 0 bytes.
2018-09-29 14:14:26,280 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-29 14:14:26,280 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000088-0000000000000001256 expecting start txid #88
2018-09-29 14:14:26,280 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000088-0000000000000001256
2018-09-29 14:14:26,349 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000088-0000000000000001256 of size 110389 edits # 1169 loaded in 0 seconds
2018-09-29 14:14:26,349 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000001256 using no compression
2018-09-29 14:14:26,359 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000001256 of size 15906 bytes saved in 0 seconds .
2018-09-29 14:14:26,545 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 87
2018-09-29 14:14:26,546 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2018-09-29 14:14:26,569 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000001256, fileSize: 15906. Sent total: 15906 bytes. Size of last segment intended to send: -1 bytes.
2018-09-29 14:14:26,603 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1256 to namenode at http://localhost:50070 in 0.035 seconds
2018-09-29 14:14:26,604 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 15906
2018-09-29 15:14:27,004 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-29 15:14:27,005 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1257&endTxId=1258&storageInfo=-63:599153523:1538219587368:CID-88860281-4205-4492-aa60-05a152b2daf2
2018-09-29 15:14:27,016 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-lag/dfs/namesecondary/current/edits_tmp_0000000000000001257-0000000000000001258_0000000000011429766 took 0.00s.
2018-09-29 15:14:27,016 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001257-0000000000000001258_0000000000011429766 size 0 bytes.
2018-09-29 15:14:27,016 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-29 15:14:27,017 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000001257-0000000000000001258 expecting start txid #1257
2018-09-29 15:14:27,017 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000001257-0000000000000001258
2018-09-29 15:14:27,017 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000001257-0000000000000001258 of size 42 edits # 2 loaded in 0 seconds
2018-09-29 15:14:27,018 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000001258 using no compression
2018-09-29 15:14:27,048 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000001258 of size 15906 bytes saved in 0 seconds .
2018-09-29 15:14:27,056 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1256
2018-09-29 15:14:27,056 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000000087, cpktTxId=0000000000000000087)
2018-09-29 15:14:27,064 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000001258, fileSize: 15906. Sent total: 15906 bytes. Size of last segment intended to send: -1 bytes.
2018-09-29 15:14:27,080 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1258 to namenode at http://localhost:50070 in 0.016 seconds
2018-09-29 15:14:27,080 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 15906
2018-09-29 16:14:27,475 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-29 16:14:27,476 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1259&endTxId=1260&storageInfo=-63:599153523:1538219587368:CID-88860281-4205-4492-aa60-05a152b2daf2
2018-09-29 16:14:27,489 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-lag/dfs/namesecondary/current/edits_tmp_0000000000000001259-0000000000000001260_0000000000015030236 took 0.00s.
2018-09-29 16:14:27,489 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001259-0000000000000001260_0000000000015030236 size 0 bytes.
2018-09-29 16:14:27,490 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-29 16:14:27,490 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000001259-0000000000000001260 expecting start txid #1259
2018-09-29 16:14:27,490 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000001259-0000000000000001260
2018-09-29 16:14:27,491 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000001259-0000000000000001260 of size 42 edits # 2 loaded in 0 seconds
2018-09-29 16:14:27,492 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000001260 using no compression
2018-09-29 16:14:27,501 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000001260 of size 15906 bytes saved in 0 seconds .
2018-09-29 16:14:27,513 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1258
2018-09-29 16:14:27,513 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000001256, cpktTxId=0000000000000001256)
2018-09-29 16:14:27,522 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000001260, fileSize: 15906. Sent total: 15906 bytes. Size of last segment intended to send: -1 bytes.
2018-09-29 16:14:27,537 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1260 to namenode at http://localhost:50070 in 0.016 seconds
2018-09-29 16:14:27,537 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 15906
2018-09-29 17:14:27,915 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-29 17:14:27,916 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1261&endTxId=1262&storageInfo=-63:599153523:1538219587368:CID-88860281-4205-4492-aa60-05a152b2daf2
2018-09-29 17:14:27,924 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-lag/dfs/namesecondary/current/edits_tmp_0000000000000001261-0000000000000001262_0000000000018630677 took 0.00s.
2018-09-29 17:14:27,924 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001261-0000000000000001262_0000000000018630677 size 0 bytes.
2018-09-29 17:14:27,924 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-29 17:14:27,924 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000001261-0000000000000001262 expecting start txid #1261
2018-09-29 17:14:27,924 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000001261-0000000000000001262
2018-09-29 17:14:27,924 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000001261-0000000000000001262 of size 42 edits # 2 loaded in 0 seconds
2018-09-29 17:14:27,925 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000001262 using no compression
2018-09-29 17:14:27,933 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000001262 of size 15906 bytes saved in 0 seconds .
2018-09-29 17:14:27,943 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1260
2018-09-29 17:14:27,943 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000001258, cpktTxId=0000000000000001258)
2018-09-29 17:14:27,952 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000001262, fileSize: 15906. Sent total: 15906 bytes. Size of last segment intended to send: -1 bytes.
2018-09-29 17:14:27,968 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1262 to namenode at http://localhost:50070 in 0.016 seconds
2018-09-29 17:14:27,969 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 15906
2018-09-29 18:14:28,337 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-29 18:14:28,337 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1263&endTxId=1264&storageInfo=-63:599153523:1538219587368:CID-88860281-4205-4492-aa60-05a152b2daf2
2018-09-29 18:14:28,351 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-lag/dfs/namesecondary/current/edits_tmp_0000000000000001263-0000000000000001264_0000000000022231098 took 0.00s.
2018-09-29 18:14:28,351 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001263-0000000000000001264_0000000000022231098 size 0 bytes.
2018-09-29 18:14:28,351 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-29 18:14:28,351 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000001263-0000000000000001264 expecting start txid #1263
2018-09-29 18:14:28,352 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000001263-0000000000000001264
2018-09-29 18:14:28,352 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000001263-0000000000000001264 of size 42 edits # 2 loaded in 0 seconds
2018-09-29 18:14:28,352 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000001264 using no compression
2018-09-29 18:14:28,356 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000001264 of size 15906 bytes saved in 0 seconds .
2018-09-29 18:14:28,369 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1262
2018-09-29 18:14:28,369 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000001260, cpktTxId=0000000000000001260)
2018-09-29 18:14:28,384 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000001264, fileSize: 15906. Sent total: 15906 bytes. Size of last segment intended to send: -1 bytes.
2018-09-29 18:14:28,416 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1264 to namenode at http://localhost:50070 in 0.033 seconds
2018-09-29 18:14:28,416 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 15906
2018-09-29 19:14:28,740 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-29 19:14:28,741 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1265&endTxId=1266&storageInfo=-63:599153523:1538219587368:CID-88860281-4205-4492-aa60-05a152b2daf2
2018-09-29 19:14:28,752 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-lag/dfs/namesecondary/current/edits_tmp_0000000000000001265-0000000000000001266_0000000000025831502 took 0.00s.
2018-09-29 19:14:28,752 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001265-0000000000000001266_0000000000025831502 size 0 bytes.
2018-09-29 19:14:28,753 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-29 19:14:28,753 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000001265-0000000000000001266 expecting start txid #1265
2018-09-29 19:14:28,753 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000001265-0000000000000001266
2018-09-29 19:14:28,754 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000001265-0000000000000001266 of size 42 edits # 2 loaded in 0 seconds
2018-09-29 19:14:28,755 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000001266 using no compression
2018-09-29 19:14:28,767 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000001266 of size 15906 bytes saved in 0 seconds .
2018-09-29 19:14:28,777 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1264
2018-09-29 19:14:28,777 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000001262, cpktTxId=0000000000000001262)
2018-09-29 19:14:28,794 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000001266, fileSize: 15906. Sent total: 15906 bytes. Size of last segment intended to send: -1 bytes.
2018-09-29 19:14:28,819 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1266 to namenode at http://localhost:50070 in 0.025 seconds
2018-09-29 19:14:28,819 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 15906
2018-09-29 20:14:29,104 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-09-29 20:14:29,104 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1267&endTxId=1268&storageInfo=-63:599153523:1538219587368:CID-88860281-4205-4492-aa60-05a152b2daf2
2018-09-29 20:14:29,118 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-lag/dfs/namesecondary/current/edits_tmp_0000000000000001267-0000000000000001268_0000000000029431865 took 0.00s.
2018-09-29 20:14:29,118 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000001267-0000000000000001268_0000000000029431865 size 0 bytes.
2018-09-29 20:14:29,118 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-09-29 20:14:29,118 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000001267-0000000000000001268 expecting start txid #1267
2018-09-29 20:14:29,118 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000001267-0000000000000001268
2018-09-29 20:14:29,118 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000001267-0000000000000001268 of size 42 edits # 2 loaded in 0 seconds
2018-09-29 20:14:29,119 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000001268 using no compression
2018-09-29 20:14:29,124 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000001268 of size 15906 bytes saved in 0 seconds .
2018-09-29 20:14:29,134 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1266
2018-09-29 20:14:29,134 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000001264, cpktTxId=0000000000000001264)
2018-09-29 20:14:29,143 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000001268, fileSize: 15906. Sent total: 15906 bytes. Size of last segment intended to send: -1 bytes.
2018-09-29 20:14:29,159 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1268 to namenode at http://localhost:50070 in 0.017 seconds
2018-09-29 20:14:29,159 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 15906
2018-09-29 20:34:29,256 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2018-09-29 20:34:29,258 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at lag-Predator-G3-571/127.0.1.1
************************************************************/
2018-10-01 15:40:32,835 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = lag-Predator-G3-571/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.1
STARTUP_MSG:   classpath = /home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/etc/hadoop:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/activation-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/xz-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hadoop-auth-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jettison-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/junit-4.11.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/avro-1.7.7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hadoop-annotations-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsch-0.1.54.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-common-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-nfs-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/fst-2.50.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-router-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-registry-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-api-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.1.jar:/usr/lib/jvm/java-8-openjdk-amd64//lib/tools.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e30710aea4e6e55e69372929106cf119af06fd0e; compiled by 'root' on 2018-04-16T09:33Z
STARTUP_MSG:   java = 1.8.0_181
************************************************************/
2018-10-01 15:40:32,900 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2018-10-01 15:40:33,109 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-10-01 15:40:33,148 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-10-01 15:40:33,148 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2018-10-01 15:40:33,275 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2018-10-01 15:40:33,310 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-lag/dfs/namesecondary/in_use.lock acquired by nodename 6914@lag-Predator-G3-571
2018-10-01 15:40:33,318 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2018-10-01 15:40:33,318 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2018-10-01 15:40:33,320 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2018-10-01 15:40:33,320 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = lag (auth:SIMPLE)
2018-10-01 15:40:33,320 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2018-10-01 15:40:33,320 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2018-10-01 15:40:33,320 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2018-10-01 15:40:33,340 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2018-10-01 15:40:33,350 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2018-10-01 15:40:33,350 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2018-10-01 15:40:33,351 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2018-10-01 15:40:33,352 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2018 Oct 01 15:40:33
2018-10-01 15:40:33,352 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2018-10-01 15:40:33,352 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-10-01 15:40:33,353 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2018-10-01 15:40:33,353 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2018-10-01 15:40:33,361 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2018-10-01 15:40:33,361 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.heartbeat.interval(3) assuming SECONDS
2018-10-01 15:40:33,363 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2018-10-01 15:40:33,364 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2018-10-01 15:40:33,364 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2018-10-01 15:40:33,364 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2018-10-01 15:40:33,364 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2018-10-01 15:40:33,364 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2018-10-01 15:40:33,364 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2018-10-01 15:40:33,364 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2018-10-01 15:40:33,365 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2018-10-01 15:40:33,365 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2018-10-01 15:40:33,365 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2018-10-01 15:40:33,366 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2018-10-01 15:40:33,402 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2018-10-01 15:40:33,402 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-10-01 15:40:33,402 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2018-10-01 15:40:33,402 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2018-10-01 15:40:33,403 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2018-10-01 15:40:33,403 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2018-10-01 15:40:33,403 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2018-10-01 15:40:33,404 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: falseskipCaptureAccessTimeOnlyChange: false
2018-10-01 15:40:33,407 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2018-10-01 15:40:33,407 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-10-01 15:40:33,407 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2018-10-01 15:40:33,407 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2018-10-01 15:40:33,409 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2018-10-01 15:40:33,409 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2018-10-01 15:40:33,409 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2018-10-01 15:40:33,421 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2018-10-01 15:40:33,421 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2018-10-01 15:40:33,427 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2018-10-01 15:40:33,469 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-10-01 15:40:33,476 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-10-01 15:40:33,480 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2018-10-01 15:40:33,483 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-10-01 15:40:33,484 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2018-10-01 15:40:33,484 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-10-01 15:40:33,484 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-10-01 15:40:33,493 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2018-10-01 15:40:33,493 INFO org.mortbay.log: jetty-6.1.26
2018-10-01 15:40:33,625 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2018-10-01 15:40:33,625 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2018-10-01 15:41:20,802 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2018-10-01 15:41:20,805 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at lag-Predator-G3-571/127.0.1.1
************************************************************/
2018-10-01 15:41:45,519 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = lag-Predator-G3-571/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.1
STARTUP_MSG:   classpath = /home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/etc/hadoop:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/activation-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/xz-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hadoop-auth-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jettison-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/junit-4.11.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/avro-1.7.7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hadoop-annotations-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsch-0.1.54.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-common-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-nfs-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/fst-2.50.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-router-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-registry-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-api-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.1.jar:/usr/lib/jvm/java-8-openjdk-amd64//lib/tools.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e30710aea4e6e55e69372929106cf119af06fd0e; compiled by 'root' on 2018-04-16T09:33Z
STARTUP_MSG:   java = 1.8.0_181
************************************************************/
2018-10-01 15:41:45,525 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2018-10-01 15:41:45,721 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-10-01 15:41:45,759 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-10-01 15:41:45,759 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2018-10-01 15:41:45,870 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2018-10-01 15:41:45,916 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-lag/dfs/namesecondary/in_use.lock acquired by nodename 8330@lag-Predator-G3-571
2018-10-01 15:41:45,937 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2018-10-01 15:41:45,939 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2018-10-01 15:41:45,943 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2018-10-01 15:41:45,943 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = lag (auth:SIMPLE)
2018-10-01 15:41:45,944 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2018-10-01 15:41:45,944 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2018-10-01 15:41:45,944 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2018-10-01 15:41:45,968 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2018-10-01 15:41:45,978 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2018-10-01 15:41:45,978 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2018-10-01 15:41:45,980 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2018-10-01 15:41:45,980 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2018 Oct 01 15:41:45
2018-10-01 15:41:45,981 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2018-10-01 15:41:45,981 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-10-01 15:41:45,982 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2018-10-01 15:41:45,982 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2018-10-01 15:41:45,989 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2018-10-01 15:41:45,990 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.heartbeat.interval(3) assuming SECONDS
2018-10-01 15:41:45,992 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2018-10-01 15:41:45,993 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2018-10-01 15:41:45,993 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2018-10-01 15:41:45,993 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2018-10-01 15:41:45,993 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2018-10-01 15:41:45,993 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2018-10-01 15:41:45,993 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2018-10-01 15:41:45,993 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2018-10-01 15:41:45,993 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2018-10-01 15:41:45,993 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2018-10-01 15:41:45,993 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2018-10-01 15:41:45,995 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2018-10-01 15:41:46,028 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2018-10-01 15:41:46,029 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-10-01 15:41:46,029 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2018-10-01 15:41:46,029 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2018-10-01 15:41:46,029 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2018-10-01 15:41:46,029 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2018-10-01 15:41:46,029 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2018-10-01 15:41:46,031 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: falseskipCaptureAccessTimeOnlyChange: false
2018-10-01 15:41:46,033 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2018-10-01 15:41:46,033 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-10-01 15:41:46,033 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2018-10-01 15:41:46,033 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2018-10-01 15:41:46,035 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2018-10-01 15:41:46,035 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2018-10-01 15:41:46,035 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2018-10-01 15:41:46,041 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2018-10-01 15:41:46,041 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2018-10-01 15:41:46,045 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2018-10-01 15:41:46,078 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-10-01 15:41:46,083 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-10-01 15:41:46,086 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2018-10-01 15:41:46,090 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-10-01 15:41:46,091 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2018-10-01 15:41:46,091 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-10-01 15:41:46,091 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-10-01 15:41:46,100 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2018-10-01 15:41:46,100 INFO org.mortbay.log: jetty-6.1.26
2018-10-01 15:41:46,224 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2018-10-01 15:41:46,224 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2018-10-01 16:24:47,291 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2018-10-01 16:24:47,419 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=0&storageInfo=-63:758020841:1538401289851:CID-a777b8f1-3585-4228-96aa-cd08fe28d2e5&bootstrapstandby=false
2018-10-01 16:24:47,431 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2018-10-01 16:24:47,791 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000000000 took 0.00s.
2018-10-01 16:24:47,791 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 320 bytes.
2018-10-01 16:24:48,023 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1&endTxId=1284&storageInfo=-63:758020841:1538401289851:CID-a777b8f1-3585-4228-96aa-cd08fe28d2e5
2018-10-01 16:24:48,270 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 115000.00 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-lag/dfs/namesecondary/current/edits_tmp_0000000000000000001-0000000000000001284_0000000000003623373 took 0.00s.
2018-10-01 16:24:48,271 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000001284_0000000000003623373 size 0 bytes.
2018-10-01 16:24:48,332 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2018-10-01 16:24:48,347 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2018-10-01 16:24:48,348 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000000000
2018-10-01 16:24:48,348 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2018-10-01 16:24:48,351 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-10-01 16:24:48,354 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000001-0000000000000001284 expecting start txid #1
2018-10-01 16:24:48,354 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000001-0000000000000001284
2018-10-01 16:24:48,468 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000001-0000000000000001284 of size 118340 edits # 1284 loaded in 0 seconds
2018-10-01 16:24:48,471 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000001284 using no compression
2018-10-01 16:24:48,501 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000001284 of size 16153 bytes saved in 0 seconds .
2018-10-01 16:24:48,707 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-lag/dfs/namesecondary
2018-10-01 16:24:48,711 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-lag/dfs/namesecondary
2018-10-01 16:24:48,930 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000001284, fileSize: 16153. Sent total: 16153 bytes. Size of last segment intended to send: -1 bytes.
2018-10-01 16:24:49,435 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1284 to namenode at http://localhost:50070 in 0.519 seconds
2018-10-01 16:24:49,435 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 16153
2018-10-01 16:46:57,059 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2018-10-01 16:46:57,066 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at lag-Predator-G3-571/127.0.1.1
************************************************************/
2018-10-01 21:51:21,299 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting SecondaryNameNode
STARTUP_MSG:   host = lag-Predator-G3-571/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.1
STARTUP_MSG:   classpath = /home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/etc/hadoop:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/activation-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/xz-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hadoop-auth-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jettison-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/junit-4.11.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/gson-2.2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/avro-1.7.7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hadoop-annotations-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jsch-0.1.54.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-common-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-nfs-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/common/hadoop-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/fst-2.50.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-client-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-router-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-registry-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-api-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/yarn/hadoop-yarn-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1-tests.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.1.jar:/home/lag/Git/All/BD/Hadoop/hadoop-2.9.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.1.jar:/usr/lib/jvm/java-8-openjdk-amd64//lib/tools.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e30710aea4e6e55e69372929106cf119af06fd0e; compiled by 'root' on 2018-04-16T09:33Z
STARTUP_MSG:   java = 1.8.0_181
************************************************************/
2018-10-01 21:51:21,342 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2018-10-01 21:51:21,550 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-10-01 21:51:21,590 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-10-01 21:51:21,590 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
2018-10-01 21:51:21,708 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2018-10-01 21:51:21,747 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-lag/dfs/namesecondary/in_use.lock acquired by nodename 7858@lag-Predator-G3-571
2018-10-01 21:51:21,753 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2018-10-01 21:51:21,754 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2018-10-01 21:51:21,755 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2018-10-01 21:51:21,756 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = lag (auth:SIMPLE)
2018-10-01 21:51:21,756 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2018-10-01 21:51:21,756 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2018-10-01 21:51:21,756 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2018-10-01 21:51:21,773 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2018-10-01 21:51:21,783 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2018-10-01 21:51:21,783 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2018-10-01 21:51:21,785 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2018-10-01 21:51:21,785 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2018 Oct 01 21:51:21
2018-10-01 21:51:21,786 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2018-10-01 21:51:21,786 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-10-01 21:51:21,787 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2018-10-01 21:51:21,787 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2018-10-01 21:51:21,795 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2018-10-01 21:51:21,795 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.heartbeat.interval(3) assuming SECONDS
2018-10-01 21:51:21,798 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2018-10-01 21:51:21,799 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2018-10-01 21:51:21,799 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2018-10-01 21:51:21,799 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2018-10-01 21:51:21,799 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
2018-10-01 21:51:21,799 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2018-10-01 21:51:21,799 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2018-10-01 21:51:21,799 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2018-10-01 21:51:21,799 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2018-10-01 21:51:21,799 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2018-10-01 21:51:21,799 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2018-10-01 21:51:21,800 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2018-10-01 21:51:21,840 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2018-10-01 21:51:21,840 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-10-01 21:51:21,840 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2018-10-01 21:51:21,840 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2018-10-01 21:51:21,840 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2018-10-01 21:51:21,840 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2018-10-01 21:51:21,840 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2018-10-01 21:51:21,842 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: falseskipCaptureAccessTimeOnlyChange: false
2018-10-01 21:51:21,845 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2018-10-01 21:51:21,845 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2018-10-01 21:51:21,845 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2018-10-01 21:51:21,845 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2018-10-01 21:51:21,847 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2018-10-01 21:51:21,847 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2018-10-01 21:51:21,847 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2018-10-01 21:51:21,854 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
2018-10-01 21:51:21,854 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
2018-10-01 21:51:21,860 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:50090
2018-10-01 21:51:21,906 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-10-01 21:51:21,913 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-10-01 21:51:21,916 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
2018-10-01 21:51:21,920 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-10-01 21:51:21,921 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2018-10-01 21:51:21,922 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-10-01 21:51:21,922 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-10-01 21:51:21,930 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50090
2018-10-01 21:51:21,930 INFO org.mortbay.log: jetty-6.1.26
2018-10-01 21:51:22,085 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50090
2018-10-01 21:51:22,085 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
2018-10-01 21:52:22,280 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
2018-10-01 21:52:22,806 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getimage=1&txid=0&storageInfo=-63:1549815022:1538423468728:CID-7d3148c9-dcc7-444c-8096-e10ab44c02b7&bootstrapstandby=false
2018-10-01 21:52:22,904 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
2018-10-01 21:52:23,094 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000000000 took 0.00s.
2018-10-01 21:52:23,094 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 320 bytes.
2018-10-01 21:52:23,108 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=1&endTxId=560&storageInfo=-63:1549815022:1538423468728:CID-7d3148c9-dcc7-444c-8096-e10ab44c02b7
2018-10-01 21:52:23,116 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 48000.00 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-lag/dfs/namesecondary/current/edits_tmp_0000000000000000001-0000000000000000560_0000000000007896354 took 0.00s.
2018-10-01 21:52:23,116 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000000560_0000000000007896354 size 0 bytes.
2018-10-01 21:52:23,153 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2018-10-01 21:52:23,169 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2018-10-01 21:52:23,169 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000000000
2018-10-01 21:52:23,169 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2018-10-01 21:52:23,173 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-10-01 21:52:23,176 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000560 expecting start txid #1
2018-10-01 21:52:23,176 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000560
2018-10-01 21:52:23,253 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000560 of size 50113 edits # 560 loaded in 0 seconds
2018-10-01 21:52:23,257 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000000560 using no compression
2018-10-01 21:52:23,285 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000000560 of size 7377 bytes saved in 0 seconds .
2018-10-01 21:52:23,298 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-lag/dfs/namesecondary
2018-10-01 21:52:23,301 INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-lag/dfs/namesecondary
2018-10-01 21:52:23,363 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000000560, fileSize: 7377. Sent total: 7377 bytes. Size of last segment intended to send: -1 bytes.
2018-10-01 21:52:23,493 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 560 to namenode at http://localhost:50070 in 0.176 seconds
2018-10-01 21:52:23,493 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 7377
2018-10-01 22:52:23,925 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has not changed. Will not download image.
2018-10-01 22:52:23,926 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:50070/imagetransfer?getedit=1&startTxId=561&endTxId=1311&storageInfo=-63:1549815022:1538423468728:CID-7d3148c9-dcc7-444c-8096-e10ab44c02b7
2018-10-01 22:52:23,950 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 69000.00 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-lag/dfs/namesecondary/current/edits_tmp_0000000000000000561-0000000000000001311_0000000000011497171 took 0.00s.
2018-10-01 22:52:23,950 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000561-0000000000000001311_0000000000011497171 size 0 bytes.
2018-10-01 22:52:23,951 INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
2018-10-01 22:52:23,951 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000561-0000000000000001311 expecting start txid #561
2018-10-01 22:52:23,952 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000561-0000000000000001311
2018-10-01 22:52:23,987 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-lag/dfs/namesecondary/current/edits_0000000000000000561-0000000000000001311 of size 71213 edits # 751 loaded in 0 seconds
2018-10-01 22:52:23,988 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000001311 using no compression
2018-10-01 22:52:23,996 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-lag/dfs/namesecondary/current/fsimage.ckpt_0000000000000001311 of size 16352 bytes saved in 0 seconds .
2018-10-01 22:52:24,015 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 560
2018-10-01 22:52:24,015 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2018-10-01 22:52:24,025 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /tmp/hadoop-lag/dfs/namesecondary/current/fsimage_0000000000000001311, fileSize: 16352. Sent total: 16352 bytes. Size of last segment intended to send: -1 bytes.
2018-10-01 22:52:24,050 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 1311 to namenode at http://localhost:50070 in 0.026 seconds
2018-10-01 22:52:24,051 WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 16352
2018-10-01 23:43:17,704 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
2018-10-01 23:43:17,706 INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down SecondaryNameNode at lag-Predator-G3-571/127.0.1.1
************************************************************/
